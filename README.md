# ğŸš€ MLOps Project - Pipeline Completo de Machine Learning

[![Docker](https://img.shields.io/badge/Docker-Enabled-blue)](https://www.docker.com/)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.9.3-green)](https://airflow.apache.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Latest-orange)](https://mlflow.org/)
[![Python](https://img.shields.io/badge/Python-3.11-blue)](https://python.org/)

## ğŸ“‹ Trabajo Final - MLOps 1

Este proyecto constituye el **Trabajo Final** para la materia **MLOps 1** del programa de posgrado. Se dedicÃ³ a la implementaciÃ³n de un pipeline completo de Machine Learning Operations (MLOps) que integra las mejores prÃ¡cticas de la industria para el desarrollo, despliegue y monitoreo de modelos de machine learning en producciÃ³n.

El proyecto se enfoca en la **automatizaciÃ³n del proceso de entrenamiento** de modelos de regresiÃ³n utilizando tÃ©cnicas de aprendizaje automÃ¡tico, especÃ­ficamente implementando un **RandomForestRegressor** para la predicciÃ³n de descuentos comerciales. La soluciÃ³n combina **Apache Airflow** para la orquestaciÃ³n de workflows y **MLflow** para el tracking de experimentos y modelos, todo containerizado con Docker para facilitar el despliegue y la reproducibilidad.

## ğŸ‘¥ Integrantes del Grupo

Los integrantes del grupo, ordenados alfabÃ©ticamente:

- **Calabia, Juan Manuel**
- **Canal, David**
- **CofrÃ© VillalÃ³n, Francisco**
- **Diaz, Natalia Beatriz**
- **Vasquez, Jorge**

---

Un pipeline completo de MLOps que combina **Apache Airflow** para orquestaciÃ³n de workflows y **MLflow** para tracking de experimentos y modelos. DiseÃ±ado para ser fÃ¡cil de usar desde GitHub con un solo comando.

## âœ¨ CaracterÃ­sticas

- ğŸ”„ **OrquestaciÃ³n**: Apache Airflow para workflows de ML
- ğŸ“Š **Tracking**: MLflow para experimentos y modelos
- ğŸ³ **Containerizado**: Todo en Docker para fÃ¡cil despliegue
- ğŸš€ **Setup AutomÃ¡tico**: Un comando para configurar todo
- ğŸ“ˆ **Monitoreo**: Interfaces web para Airflow y MLflow
- ğŸ”§ **Desarrollo**: Makefile con comandos Ãºtiles

## ğŸ—ï¸ Arquitectura

```mermaid
graph TB
    A[GitHub Repository] --> B[Clone & Setup]
    B --> C[Docker Compose]
    C --> D[PostgreSQL]
    C --> E[Airflow Webserver]
    C --> F[Airflow Scheduler]
    C --> G[MLflow UI]
    
    E --> H[DAGs]
    F --> H
    H --> I[Train Model Script]
    I --> J[MLflow Tracking]
    J --> G
    
    D --> E
    D --> F
```

## ğŸ“ Estructura del Proyecto

```
MLOps1/
â”œâ”€â”€ ğŸ“ dags/                    # DAGs de Airflow
â”‚   â””â”€â”€ train_model_dag.py      # DAG para entrenamiento
â”œâ”€â”€ ğŸ“ scripts/                 # Scripts de Python
â”‚   â””â”€â”€ train_model.py          # Script de entrenamiento
â”œâ”€â”€ ğŸ“ data/                    # Datos de entrenamiento
â”‚   â””â”€â”€ df.pkl                  # Dataset principal
â”œâ”€â”€ ğŸ“ mlruns/                  # MLflow tracking store
â”œâ”€â”€ ğŸ³ docker-compose.yaml      # ConfiguraciÃ³n de servicios
â”œâ”€â”€ ğŸ³ Dockerfile.airflow       # Imagen personalizada
â”œâ”€â”€ ğŸ“‹ requirements.txt         # Dependencias Python
â”œâ”€â”€ âš™ï¸ Makefile                 # Comandos Ãºtiles
â”œâ”€â”€ ğŸš€ setup.sh                 # Script de configuraciÃ³n
â”œâ”€â”€ ğŸ“– README.md                # Este archivo
â””â”€â”€ ğŸ”§ env.example              # Variables de entorno
```

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- **Docker Desktop** (versiÃ³n 4.0+)
- **Git** (para clonar el repositorio)
- **Make** (opcional, pero recomendado)

### ğŸ¯ InstalaciÃ³n en 3 Pasos

1. **Clonar el repositorio:**
   ```bash
   git clone <tu-repositorio-url>
   cd MLOps1
   ```

2. **ConfiguraciÃ³n automÃ¡tica (primera vez):**
   ```bash
   make setup
   ```
   
   âš¡ **Esto hace todo automÃ¡ticamente:**
   - Construye las imÃ¡genes Docker
   - Inicializa la base de datos
   - Crea el usuario administrador
   - Ejecuta un entrenamiento inicial
   - Configura MLflow

3. **Â¡Listo! Accede a las interfaces:**
   - ğŸŒ **Airflow UI**: http://localhost:8080
   - ğŸ“Š **MLflow UI**: http://localhost:5001
   - ğŸ‘¤ **Credenciales**: `admin` / `admin`

### ğŸ”„ Uso Diario

```bash
# Levantar servicios (despuÃ©s de la primera vez)
make up

# Ver estado de servicios
make status

# Ver logs en tiempo real
make logs

# Ejecutar entrenamiento manual
make train

# Abrir interfaces web
make ui

# Parar servicios
make down
```

## ğŸ“‹ Comandos Disponibles

| Comando | DescripciÃ³n | CuÃ¡ndo usar |
|---------|-------------|-------------|
| `make setup` | ğŸš€ ConfiguraciÃ³n inicial completa | **Solo primera vez** |
| `make up` | â¬†ï¸ Levantar servicios | Uso diario |
| `make down` | â¬‡ï¸ Parar servicios | Al terminar |
| `make restart` | ğŸ”„ Reiniciar servicios | Si hay problemas |
| `make status` | ğŸ“Š Ver estado de contenedores | Verificar estado |
| `make logs` | ğŸ“ Ver logs de todos los servicios | Debugging |
| `make train` | ğŸ¤– Ejecutar entrenamiento | Entrenar modelo |
| `make ui` | ğŸŒ Abrir interfaces web | Acceso rÃ¡pido |
| `make clean` | ğŸ§¹ Limpiar todo | Reset completo |
| `make reset` | ğŸ”„ Reset completo | Empezar de cero |

## ğŸ¯ Uso de las Interfaces

### ğŸ“Š Airflow UI (http://localhost:8080)

1. **Inicia sesiÃ³n** con `admin` / `admin`
2. Ve a la pestaÃ±a **"DAGs"**
3. Encuentra el DAG `entrenamiento_modelo_ml`
4. **Activa el DAG** (toggle switch)
5. **Ejecuta manualmente** si es necesario

**Funcionalidades:**
- Monitoreo de workflows
- EjecuciÃ³n manual de DAGs
- VisualizaciÃ³n de logs
- GestiÃ³n de usuarios

### ğŸ§ª MLflow UI (http://localhost:5001)

1. Ve a la pestaÃ±a **"Experiments"**
2. Selecciona el experimento **"Default"**
3. **Explora los runs** de entrenamiento
4. **Compara mÃ©tricas** entre runs
5. **Descarga modelos** entrenados

**Funcionalidades:**
- Tracking de experimentos
- ComparaciÃ³n de modelos
- VisualizaciÃ³n de mÃ©tricas
- Descarga de artefactos

## ğŸ¤– Entrenamiento de Modelos

### Script de Entrenamiento

El script `scripts/train_model.py` entrena un **RandomForestRegressor** con:

- **ğŸ“Š Datos**: Carga desde `data/df.pkl`
- **ğŸ¯ Target**: Variable `descuento`
- **ğŸ“ˆ MÃ©tricas**: MAE, RMSE, R2, tiempo de entrenamiento
- **ğŸ“ Tracking**: ParÃ¡metros y mÃ©tricas en MLflow

### ParÃ¡metros del Modelo

```python
best_params = {
    'n_estimators': 30,
    'max_depth': 12,
    'min_samples_split': 2,
    'min_samples_leaf': 1
}
```

### Ejecutar Entrenamiento

```bash
# OpciÃ³n 1: Desde Airflow UI
# Activa el DAG y ejecuta manualmente

# OpciÃ³n 2: Desde terminal
make train

# OpciÃ³n 3: Directo con Docker
docker compose exec airflow-webserver python /opt/airflow/scripts/train_model.py
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

Copia `env.example` a `.env` y modifica segÃºn necesites:

```bash
cp env.example .env
```

### Puertos Personalizados

Si necesitas cambiar los puertos, edita `docker-compose.yaml`:

```yaml
ports:
  - "8080:8080"  # Airflow UI
  - "5001:5000"  # MLflow UI
  - "5432:5432"  # PostgreSQL
```

### Agregar Datos

1. Coloca tu archivo de datos en `data/df.pkl`
2. AsegÃºrate de que tenga la columna `descuento`
3. Reinicia los servicios: `make restart`

## ğŸ” Troubleshooting

### âŒ Problemas Comunes

| Problema | SoluciÃ³n |
|----------|----------|
| **"Database not initialized"** | `make init` |
| **Servicios no arrancan** | `make clean && make setup` |
| **Error de permisos** | `chmod -R 777 mlruns/` |
| **Puerto ocupado** | Cambia puertos en `docker-compose.yaml` |
| **Sin datos** | Coloca `df.pkl` en `data/` |

### ğŸ” VerificaciÃ³n de Estado

```bash
# Ver contenedores corriendo
make ps

# Ver logs en tiempo real
make logs

# Ver logs especÃ­ficos
make logs-airflow
make logs-mlflow

# Verificar conectividad
curl http://localhost:8080/health
curl http://localhost:5001/health
```

### ğŸ†˜ Reset Completo

Si todo falla, haz un reset completo:

```bash
make reset
```

Esto limpia todo y vuelve a configurar desde cero.

## ğŸ› ï¸ Desarrollo

### Agregar Nuevos DAGs

1. Crea el archivo en `dags/`
2. Sigue el patrÃ³n de `train_model_dag.py`
3. Reinicia Airflow: `make restart`

### Modificar Scripts

1. Edita `scripts/train_model.py`
2. Los cambios se reflejan automÃ¡ticamente
3. Ejecuta: `make train`

### Agregar Dependencias

1. Edita `requirements.txt`
2. Reconstruye: `make build`
3. Reinicia: `make restart`

## ğŸ“¦ TecnologÃ­as

| TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|---------|-----------|
| **Apache Airflow** | 2.9.3 | OrquestaciÃ³n de workflows |
| **MLflow** | Latest | Tracking de experimentos |
| **PostgreSQL** | 13 | Base de datos |
| **Python** | 3.11 | Lenguaje de programaciÃ³n |
| **Docker** | Latest | ContainerizaciÃ³n |
| **scikit-learn** | Latest | Machine Learning |

## ğŸ¤ ContribuciÃ³n

1. Fork el repositorio
2. Crea una rama: `git checkout -b feature/nueva-funcionalidad`
3. Commit: `git commit -m 'Agregar nueva funcionalidad'`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto es parte del trabajo final de MLOps.

## ğŸ†˜ Soporte

Si tienes problemas:

1. Revisa la secciÃ³n [Troubleshooting](#-troubleshooting)
2. Verifica los logs: `make logs`
3. Haz un reset: `make reset`
4. Abre un issue en GitHub

---
